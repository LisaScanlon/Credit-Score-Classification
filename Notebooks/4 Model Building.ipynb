{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa29ba36",
   "metadata": {},
   "source": [
    "# Model Building Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6750f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the data from the pickle file\n",
    "with open('train_test_data.pkl', 'rb') as f:\n",
    "    X_train, X_test, y_train, y_test = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13deb01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cf9e367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluding the unncessary columns from the input features for the models by dropping them now\n",
    "columns_to_exclude = ['ID', 'Customer_ID', 'Month', 'SSN', 'Type_of_Loan', 'Name']  # List of columns to exclude\n",
    "X_train = X_train.drop(columns=columns_to_exclude)\n",
    "X_test = X_test.drop(columns=columns_to_exclude)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb02bc0",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95f01269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.655313561940068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lisal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Train the logistic regression model\n",
    "logistic_regression_model = LogisticRegression()\n",
    "logistic_regression_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions using logistic regression model\n",
    "logistic_regression_preds = logistic_regression_model.predict(X_test)\n",
    "\n",
    "# Evaluate the logistic regression model\n",
    "logistic_regression_accuracy = logistic_regression_model.score(X_test, y_test)\n",
    "print(\"Logistic Regression Accuracy:\", logistic_regression_accuracy)\n",
    "\n",
    "# All of the other models follow the same basic procedures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edd7f1f",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1789e0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6706827309236948\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(criterion = 'entropy', n_estimators = 500, max_depth = 5, random_state = 101)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "rf_score = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "print(rf_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5febf63e",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2ca0b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM Accuracy: 0.7219647822057461\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Machine (XGBoost)\n",
    "gbm = GradientBoostingClassifier()\n",
    "gbm.fit(X_train, y_train)\n",
    "y_pred_gbm = gbm.predict(X_test)\n",
    "gbm_score = accuracy_score(y_test, y_pred_gbm)\n",
    "print(\"GBM Accuracy:\", gbm_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2923e88d",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3c4f3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.6574760580784678\n"
     ]
    }
   ],
   "source": [
    "# This one takes a while to run\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "svm_score = accuracy_score(y_test, y_pred_svm)\n",
    "print(\"SVM Accuracy:\", svm_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a736ff",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94417d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy: 0.6898362681495211\n"
     ]
    }
   ],
   "source": [
    "# K-Nearest Neighbors\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "knn_score = accuracy_score(y_test, y_pred_knn)\n",
    "print(\"KNN Accuracy:\", knn_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6c8287",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c7c6995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.6105189990732159\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred_nb = nb.predict(X_test)\n",
    "nb_score = accuracy_score(y_test, y_pred_nb)\n",
    "print(\"Naive Bayes Accuracy:\", nb_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6110aa8e",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45cf8eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Accuracy: 0.7144732777262898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lisal\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Neural Network\n",
    "mlp = MLPClassifier()\n",
    "mlp.fit(X_train, y_train)\n",
    "y_pred_mlp = mlp.predict(X_test)\n",
    "mlp_score = accuracy_score(y_test, y_pred_mlp)\n",
    "print(\"Neural Network Accuracy:\", mlp_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947773ce",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e709106b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.7391102873030584\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "dt_score = accuracy_score(y_test, y_pred_dt)\n",
    "print(\"Decision Tree Accuracy:\", dt_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643521ed",
   "metadata": {},
   "source": [
    "## Ensemble Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d19265f",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5965bd0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Classifier Accuracy: 0.7893110905159098\n"
     ]
    }
   ],
   "source": [
    "# Ensemble Methods - Bagging\n",
    "bagging = BaggingClassifier()\n",
    "bagging.fit(X_train, y_train)\n",
    "y_pred_bagging = bagging.predict(X_test)\n",
    "bagging_score = accuracy_score(y_test, y_pred_bagging)\n",
    "print(\"Bagging Classifier Accuracy:\", bagging_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64218773",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6933f307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Classifier Accuracy: 0.6731541550818659\n"
     ]
    }
   ],
   "source": [
    "# Ensemble Methods - AdaBoost\n",
    "adaboost = AdaBoostClassifier()\n",
    "adaboost.fit(X_train, y_train)\n",
    "y_pred_adaboost = adaboost.predict(X_test)\n",
    "adaboost_score = accuracy_score(y_test, y_pred_adaboost)\n",
    "print(\"AdaBoost Classifier Accuracy:\", adaboost_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fb026c",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d79143a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Classifier Accuracy: 0.7925548347235094\n"
     ]
    }
   ],
   "source": [
    "# Ensemble Methods - Stacking (running this one takes a long time)\n",
    "estimators = [('dt', DecisionTreeClassifier()), ('bagging', BaggingClassifier()), ('gbm', GradientBoostingClassifier())]\n",
    "stacking = StackingClassifier(estimators=estimators)\n",
    "stacking.fit(X_train, y_train)\n",
    "y_pred_stacking = stacking.predict(X_test)\n",
    "stacking_score = accuracy_score(y_test, y_pred_stacking)\n",
    "print(\"Stacking Classifier Accuracy:\", stacking_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a8c5ee",
   "metadata": {},
   "source": [
    "Although the Stacking ensemble method had a slightly higher accuracy, we will use Baggin s our final model because the computation time is significantly faster, and the accuracy is only about 0.003 worse than the stacking model. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
