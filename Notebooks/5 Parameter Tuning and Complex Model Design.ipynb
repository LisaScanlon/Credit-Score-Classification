{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ba8d0be",
   "metadata": {},
   "source": [
    "# Parameter Tuning and Complex Model Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3f6299b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redo the original bagging model for comparison purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c086c4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the data from the pickle file\n",
    "with open('train_test_data.pkl', 'rb') as f:\n",
    "    X_train_full, X_test_full, y_train_full, y_test_full = pickle.load(f)\n",
    "\n",
    "# Randomly sample just 1/10 of the data records to speed up the computation time\n",
    "X_train = X_train_full.sample(frac=0.01, random_state=101)\n",
    "y_train = y_train_full.loc[X_train.index]\n",
    "\n",
    "# Test set remains unchanged\n",
    "X_test = X_test_full\n",
    "y_test = y_test_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ffe4835",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4722f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluding the unncessary columns from the input features for the models by dropping them now\n",
    "columns_to_exclude = ['ID', 'Customer_ID', 'Month', 'SSN', 'Type_of_Loan', 'Name', 'Annual_Income']  # List of columns to exclude\n",
    "# Notice how we are also excluding monthly_inhand_salary because that variable shows signs of multicollinearity with annual_income\n",
    "X_train = X_train.drop(columns=columns_to_exclude)\n",
    "X_test = X_test.drop(columns=columns_to_exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed547e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Classifier Accuracy: 0.6477448254556688\n"
     ]
    }
   ],
   "source": [
    "# Ensemble Methods - Bagging\n",
    "bagging = BaggingClassifier()\n",
    "bagging.fit(X_train, y_train)\n",
    "y_pred_bagging = bagging.predict(X_test)\n",
    "bagging_score = accuracy_score(y_test, y_pred_bagging)\n",
    "print(\"Bagging Classifier Accuracy:\", bagging_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbd41df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XG Boost Classifier Accuracy: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode the target variable\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Instantiate XGBoost classifier\n",
    "xgb_classifier = xgb.XGBClassifier()\n",
    "\n",
    "# Train XGBoost classifier using the encoded target variables\n",
    "xgb_classifier.fit(X_train, y_train_encoded)\n",
    "\n",
    "# Predict\n",
    "y_pred_xgb = xgb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy_xgb = accuracy_score(y_test_encoded, y_pred_xgb)\n",
    "print(\"XG Boost Classifier Accuracy:\", accuracy_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0fbe531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XG Boost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Good       0.50      0.80      0.61      2100\n",
      "        Poor       0.66      0.71      0.68      4018\n",
      "    Standard       0.78      0.60      0.68      6830\n",
      "\n",
      "    accuracy                           0.67     12948\n",
      "   macro avg       0.65      0.70      0.66     12948\n",
      "weighted avg       0.70      0.67      0.67     12948\n",
      "\n",
      "Bagging:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Good       0.46      0.78      0.58      2100\n",
      "        Poor       0.64      0.74      0.69      4018\n",
      "    Standard       0.79      0.55      0.65      6830\n",
      "\n",
      "    accuracy                           0.65     12948\n",
      "   macro avg       0.63      0.69      0.64     12948\n",
      "weighted avg       0.69      0.65      0.65     12948\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification reports of each of the models\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Transform predicted labels back to original classes just for XG Boost\n",
    "y_pred_xgb_original = label_encoder.inverse_transform(y_pred_xgb)\n",
    "\n",
    "print(\"XG Boost:\")\n",
    "print(classification_report(y_test, y_pred_xgb_original))\n",
    "\n",
    "print(\"Bagging:\")\n",
    "print(classification_report(y_test, y_pred_bagging))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf98bd9",
   "metadata": {},
   "source": [
    "# Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e39777d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importances: [0.03474182 0.03800521 0.02724009 0.02377532 0.03914683 0.01473854\n",
      " 0.066294   0.02427995 0.05597283 0.04281516 0.21629789 0.18426778\n",
      " 0.04236843 0.04487706 0.00232976 0.05667367 0.03797162 0.01089858\n",
      " 0.         0.00097073 0.00094526 0.00278298 0.0003224  0.00230311\n",
      " 0.00578368 0.00302646 0.00185707 0.00080761 0.00408106 0.00189306\n",
      " 0.00325648 0.00295902 0.00631654]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Get feature importances from base estimators\n",
    "importances = []\n",
    "\n",
    "for estimator in bagging.estimators_:\n",
    "    if hasattr(estimator, 'feature_importances_'):\n",
    "        importances.append(estimator.feature_importances_)\n",
    "\n",
    "# Aggregate feature importances across all base estimators\n",
    "importances = np.mean(importances, axis=0)\n",
    "print(\"Feature importances:\", importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efadabf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Monthly_Inhand_Salary', 'Num_Bank_Accounts', 'Num_Credit_Card',\n",
       "       'Interest_Rate', 'Num_of_Loan', 'Delay_from_due_date',\n",
       "       'Num_of_Delayed_Payment', 'Changed_Credit_Limit',\n",
       "       'Num_Credit_Inquiries', 'Credit_Mix', 'Outstanding_Debt',\n",
       "       'Credit_Utilization_Ratio', 'Credit_History_Age',\n",
       "       'Payment_of_Min_Amount', 'Total_EMI_per_month',\n",
       "       'Amount_invested_monthly', 'Payment_Behaviour', 'Monthly_Balance',\n",
       "       'x0_Architect', 'x0_Developer', 'x0_Doctor', 'x0_Engineer',\n",
       "       'x0_Entrepreneur', 'x0_Journalist', 'x0_Lawyer', 'x0_Manager',\n",
       "       'x0_Mechanic', 'x0_Media_Manager', 'x0_Musician', 'x0_Scientist',\n",
       "       'x0_Teacher', 'x0_Writer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get feature names\n",
    "feature_names = X_train.columns  # Assuming X_train is a DataFrame\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1a362fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Feature Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Credit_Mix</td>\n",
       "      <td>0.216298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Outstanding_Debt</td>\n",
       "      <td>0.184268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Delay_from_due_date</td>\n",
       "      <td>0.066294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Total_EMI_per_month</td>\n",
       "      <td>0.056674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Changed_Credit_Limit</td>\n",
       "      <td>0.055973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Credit_History_Age</td>\n",
       "      <td>0.044877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Num_Credit_Inquiries</td>\n",
       "      <td>0.042815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Credit_Utilization_Ratio</td>\n",
       "      <td>0.042368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Interest_Rate</td>\n",
       "      <td>0.039147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Monthly_Inhand_Salary</td>\n",
       "      <td>0.038005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Amount_invested_monthly</td>\n",
       "      <td>0.037972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.034742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Num_Bank_Accounts</td>\n",
       "      <td>0.027240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Num_of_Delayed_Payment</td>\n",
       "      <td>0.024280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Num_Credit_Card</td>\n",
       "      <td>0.023775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Num_of_Loan</td>\n",
       "      <td>0.014739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Payment_Behaviour</td>\n",
       "      <td>0.010899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>x0_Writer</td>\n",
       "      <td>0.006317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>x0_Journalist</td>\n",
       "      <td>0.005784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>x0_Media_Manager</td>\n",
       "      <td>0.004081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>x0_Scientist</td>\n",
       "      <td>0.003256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>x0_Lawyer</td>\n",
       "      <td>0.003026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>x0_Teacher</td>\n",
       "      <td>0.002959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>x0_Doctor</td>\n",
       "      <td>0.002783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Payment_of_Min_Amount</td>\n",
       "      <td>0.002330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>x0_Entrepreneur</td>\n",
       "      <td>0.002303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>x0_Musician</td>\n",
       "      <td>0.001893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>x0_Manager</td>\n",
       "      <td>0.001857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>x0_Architect</td>\n",
       "      <td>0.000971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>x0_Developer</td>\n",
       "      <td>0.000945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>x0_Mechanic</td>\n",
       "      <td>0.000808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>x0_Engineer</td>\n",
       "      <td>0.000322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Monthly_Balance</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Column  Feature Importance\n",
       "10                Credit_Mix            0.216298\n",
       "11          Outstanding_Debt            0.184268\n",
       "6        Delay_from_due_date            0.066294\n",
       "15       Total_EMI_per_month            0.056674\n",
       "8       Changed_Credit_Limit            0.055973\n",
       "13        Credit_History_Age            0.044877\n",
       "9       Num_Credit_Inquiries            0.042815\n",
       "12  Credit_Utilization_Ratio            0.042368\n",
       "4              Interest_Rate            0.039147\n",
       "1      Monthly_Inhand_Salary            0.038005\n",
       "16   Amount_invested_monthly            0.037972\n",
       "0                        Age            0.034742\n",
       "2          Num_Bank_Accounts            0.027240\n",
       "7     Num_of_Delayed_Payment            0.024280\n",
       "3            Num_Credit_Card            0.023775\n",
       "5                Num_of_Loan            0.014739\n",
       "17         Payment_Behaviour            0.010899\n",
       "32                 x0_Writer            0.006317\n",
       "24             x0_Journalist            0.005784\n",
       "28          x0_Media_Manager            0.004081\n",
       "30              x0_Scientist            0.003256\n",
       "25                 x0_Lawyer            0.003026\n",
       "31                x0_Teacher            0.002959\n",
       "21                 x0_Doctor            0.002783\n",
       "14     Payment_of_Min_Amount            0.002330\n",
       "23           x0_Entrepreneur            0.002303\n",
       "29               x0_Musician            0.001893\n",
       "26                x0_Manager            0.001857\n",
       "19              x0_Architect            0.000971\n",
       "20              x0_Developer            0.000945\n",
       "27               x0_Mechanic            0.000808\n",
       "22               x0_Engineer            0.000322\n",
       "18           Monthly_Balance            0.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_importance = pd.DataFrame({'Column': feature_names, 'Feature Importance': importances}, columns = ['Column', 'Feature Importance'])\n",
    "# Sort feature importances in descending order\n",
    "sorted_importance_df = df_importance.sort_values(by='Feature Importance', ascending=False)\n",
    "sorted_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e143fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Originally had this set to a threshold but realized if I am going to continue to rerun it and keep changing the \n",
    "# amounto f data included then I need to make this part static so that my application will still work\n",
    "dropped_features = ['Num_Bank_Accounts', 'Num_Credit_Card', 'Num_of_Loan', 'Num_Credit_Inquiries', 'Payment_of_Min_Amount', 'Payment_Behaviour', 'Monthly_Balance', 'x0_Architect', 'x0_Developer', 'x0_Doctor', 'x0_Engineer', 'x0_Entrepreneur', 'x0_Journalist', 'x0_Lawyer', 'x0_Manager', 'x0_Mechanic', 'x0_Media_Manager', 'x0_Musician', 'x0_Scientist', 'x0_Teacher', 'x0_Writer']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "317d8bbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Monthly_Inhand_Salary', 'Interest_Rate', 'Delay_from_due_date',\n",
       "       'Num_of_Delayed_Payment', 'Changed_Credit_Limit', 'Credit_Mix',\n",
       "       'Outstanding_Debt', 'Credit_Utilization_Ratio', 'Credit_History_Age',\n",
       "       'Total_EMI_per_month', 'Amount_invested_monthly'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming X_train is a DataFrame and dropped_features contains the features to be dropped\n",
    "X_train = X_train.drop(columns=dropped_features)\n",
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26bd531d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Classifier Accuracy after feature selection: 0.6539233858510967\n",
      "Bagging:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Good       0.47      0.78      0.59      2100\n",
      "        Poor       0.64      0.74      0.69      4018\n",
      "    Standard       0.80      0.56      0.66      6830\n",
      "\n",
      "    accuracy                           0.65     12948\n",
      "   macro avg       0.64      0.70      0.65     12948\n",
      "weighted avg       0.70      0.65      0.66     12948\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop the same features from X_test\n",
    "X_test = X_test.drop(columns=dropped_features)\n",
    "\n",
    "# Now rerun the model\n",
    "bagging.fit(X_train, y_train)\n",
    "y_pred_bagging = bagging.predict(X_test)\n",
    "bagging_score = accuracy_score(y_test, y_pred_bagging)\n",
    "print(\"Bagging Classifier Accuracy after feature selection:\", bagging_score)\n",
    "\n",
    "print(\"Bagging:\")\n",
    "print(classification_report(y_test, y_pred_bagging))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6cf3534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classifier Accuracy after feature selection: 0.6582483781278962\n",
      "XG Boost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Good       0.48      0.77      0.59      2100\n",
      "        Poor       0.65      0.71      0.68      4018\n",
      "    Standard       0.78      0.59      0.67      6830\n",
      "\n",
      "    accuracy                           0.66     12948\n",
      "   macro avg       0.64      0.69      0.65     12948\n",
      "weighted avg       0.69      0.66      0.66     12948\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode the target variable\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Instantiate XGBoost classifier\n",
    "xgb_classifier = xgb.XGBClassifier()\n",
    "\n",
    "# Train XGBoost classifier using the encoded target variables\n",
    "xgb_classifier.fit(X_train, y_train_encoded)\n",
    "\n",
    "# Predict\n",
    "y_pred_xgb = xgb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy_xgb = accuracy_score(y_test_encoded, y_pred_xgb)\n",
    "print(\"XGBoost Classifier Accuracy after feature selection:\", accuracy_xgb)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Transform predicted labels back to original classes just for XG Boost\n",
    "y_pred_xgb_original = label_encoder.inverse_transform(y_pred_xgb)\n",
    "\n",
    "print(\"XG Boost:\")\n",
    "print(classification_report(y_test, y_pred_xgb_original))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747e3683",
   "metadata": {},
   "source": [
    "# Parameter Tuning Section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa9bf3a",
   "metadata": {},
   "source": [
    "The Bagging model has been chosen as the final model because of its simplicity, low computation time, and high accuracy value. In this section, we will attempt to approve upon its accuracy by using parameter tuning, and other techniques. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eff1c39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default parameters:\n",
      "base_estimator : deprecated\n",
      "bootstrap : True\n",
      "bootstrap_features : False\n",
      "estimator : None\n",
      "max_features : 1.0\n",
      "max_samples : 1.0\n",
      "n_estimators : 10\n",
      "n_jobs : None\n",
      "oob_score : False\n",
      "random_state : None\n",
      "verbose : 0\n",
      "warm_start : False\n"
     ]
    }
   ],
   "source": [
    "# Access the default parameters\n",
    "default_params = bagging.get_params()\n",
    "\n",
    "# This will help decide what hyperparameters to use in the gridsearch and what values to try based on what was used in the original model\n",
    "print(\"Default parameters:\")\n",
    "for param, value in default_params.items():\n",
    "    print(param, \":\", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff8925de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lisal\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "45 fits failed out of a total of 135.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\lisal\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\lisal\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\lisal\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\lisal\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_samples' parameter of BaggingClassifier must be an int in the range [1, inf) or a float in the range (0.0, 1.0]. Got 1.3 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\lisal\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [0.74872063 0.74994763 0.75484812 0.74996259 0.75853659 0.75607512\n",
      "        nan        nan        nan 0.75730211 0.7548556  0.7560826\n",
      " 0.75364357 0.75117462 0.74995511        nan        nan        nan\n",
      " 0.74384259 0.74382762 0.7450621  0.72793656 0.72790663 0.7303681\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_features': 0.5, 'max_samples': 1.0, 'n_estimators': 500}\n",
      "Tuned Bagging Classifier Accuracy: 0.6742354031510658\n",
      "Bagging:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Good       0.47      0.78      0.59      2100\n",
      "        Poor       0.64      0.74      0.69      4018\n",
      "    Standard       0.80      0.56      0.66      6830\n",
      "\n",
      "    accuracy                           0.65     12948\n",
      "   macro avg       0.64      0.70      0.65     12948\n",
      "weighted avg       0.70      0.65      0.66     12948\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the hyperparameters grid\n",
    "param_grid = {\n",
    "    'n_estimators': [200, 500, 1000],  # Number of base estimators\n",
    "    'max_samples': [0.7, 1.0, 1.3],  # Number of samples to draw from X to train each base estimator\n",
    "    'max_features': [0.5, 0.7, 1.0]   # Number of features to draw from X to train each base estimator\n",
    "}\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator=bagging, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Get the best estimator\n",
    "best_bagging = grid_search.best_estimator_\n",
    "\n",
    "# Predict with the best estimator\n",
    "y_pred_best_bagging = best_bagging.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "best_bagging_score = accuracy_score(y_test, y_pred_best_bagging)\n",
    "print(\"Tuned Bagging Classifier Accuracy:\", best_bagging_score)\n",
    "\n",
    "print(\"Bagging:\")\n",
    "print(classification_report(y_test, y_pred_bagging))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32300b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default parameters:\n",
      "objective : multi:softprob\n",
      "use_label_encoder : None\n",
      "base_score : None\n",
      "booster : None\n",
      "callbacks : None\n",
      "colsample_bylevel : None\n",
      "colsample_bynode : None\n",
      "colsample_bytree : None\n",
      "early_stopping_rounds : None\n",
      "enable_categorical : False\n",
      "eval_metric : None\n",
      "feature_types : None\n",
      "gamma : None\n",
      "gpu_id : None\n",
      "grow_policy : None\n",
      "importance_type : None\n",
      "interaction_constraints : None\n",
      "learning_rate : None\n",
      "max_bin : None\n",
      "max_cat_threshold : None\n",
      "max_cat_to_onehot : None\n",
      "max_delta_step : None\n",
      "max_depth : None\n",
      "max_leaves : None\n",
      "min_child_weight : None\n",
      "missing : nan\n",
      "monotone_constraints : None\n",
      "n_estimators : 100\n",
      "n_jobs : None\n",
      "num_parallel_tree : None\n",
      "predictor : None\n",
      "random_state : None\n",
      "reg_alpha : None\n",
      "reg_lambda : None\n",
      "sampling_method : None\n",
      "scale_pos_weight : None\n",
      "subsample : None\n",
      "tree_method : None\n",
      "validate_parameters : None\n",
      "verbosity : None\n"
     ]
    }
   ],
   "source": [
    "# Access the default parameters\n",
    "default_params = xgb_classifier.get_params()\n",
    "\n",
    "# Print the default parameters\n",
    "print(\"Default parameters:\")\n",
    "for param, value in default_params.items():\n",
    "    print(param, \":\", value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4787997f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "Tuned XGBoost Classifier Accuracy: 0.6679023787457522\n",
      "XG Boost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Good       0.48      0.77      0.59      2100\n",
      "        Poor       0.65      0.71      0.68      4018\n",
      "    Standard       0.78      0.59      0.67      6830\n",
      "\n",
      "    accuracy                           0.66     12948\n",
      "   macro avg       0.64      0.69      0.65     12948\n",
      "weighted avg       0.69      0.66      0.66     12948\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define a grid of hyperparameters to search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.1, 0.01, 0.001]\n",
    "}\n",
    "\n",
    "# Instantiate XGBoost classifier\n",
    "xgb_classifier = xgb.XGBClassifier()\n",
    "\n",
    "# Initialize GridSearch with the defined parameter grid and cross-validation\n",
    "grid_search = GridSearchCV(estimator=xgb_classifier, param_grid=param_grid, cv=3, scoring='accuracy')\n",
    "\n",
    "# Perform GridSearch to find the best hyperparameters\n",
    "grid_search.fit(X_train, y_train_encoded)\n",
    "\n",
    "# Get the best hyperparameters found by GridSearch\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Predict using the model with the best hyperparameters\n",
    "best_xgb_classifier = grid_search.best_estimator_\n",
    "y_pred_xgb_tuned = best_xgb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy_xgb_tuned = accuracy_score(y_test_encoded, y_pred_xgb_tuned)\n",
    "print(\"Tuned XGBoost Classifier Accuracy:\", accuracy_xgb_tuned)\n",
    "\n",
    "# Transform predicted labels back to original classes just for XG Boost\n",
    "y_pred_xgb_original = label_encoder.inverse_transform(y_pred_xgb)\n",
    "\n",
    "print(\"XG Boost:\")\n",
    "print(classification_report(y_test, y_pred_xgb_original))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a056ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_bagging_model.pkl']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(best_bagging, 'best_bagging_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b99e1ae",
   "metadata": {},
   "source": [
    "# Final Model Design"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
